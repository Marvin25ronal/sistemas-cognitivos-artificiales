{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktFg2jj3jTE6"
   },
   "source": [
    "# ACTIVIDAD DE CLASIFICACIÓN DE TEXTO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZ-OuW5DiLJs"
   },
   "source": [
    "En esta actividad vamos a trabajar en clasificar textos. Se recorrerá todo el proceso desde traer el dataset hasta proceder a dicha clasificación. Durante la actividad se llevarán a cabo muchos procesos como la creación de un vocabulario, el uso de embeddings y la creación de modelos.\n",
    "\n",
    "Las cuestiones presentes en esta actividad están basadas en un Notebook creado por François Chollet, uno de los creadores de Keras y autor del libro \"Deep Learning with Python\". \n",
    "\n",
    "En este Notebook se trabaja con el dataset \"Newsgroup20\" que contiene aproximadamente 20000 mensajes que pertenecen a 20 categorías diferentes.\n",
    "\n",
    "El objetivo es entender los conceptos que se trabajan y ser capaz de hacer pequeñas experimentaciones para mejorar el Notebook creado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hytURWLLjZvT"
   },
   "source": [
    "#Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "DbxRuvOwkzSs"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PXfYbCflkQYy"
   },
   "source": [
    "# Descarga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e-1ZhOf3lB_A",
    "outputId": "26042aca-e8cc-4736-ca59-9eb632598ecf"
   },
   "outputs": [],
   "source": [
    "data_path = keras.utils.get_file(\n",
    "    \"news20.tar.gz\",\n",
    "    \"http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz\",\n",
    "    untar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l3ygvoWhlCYj",
    "outputId": "1e8b6fba-a96d-4f59-c2bb-c2ec9402e1b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of directories: 20\n",
      "Directory names: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "#Estructura de directorios del dataset\n",
    "data_dir = pathlib.Path(data_path).parent / \"20_newsgroup\"\n",
    "dirnames = os.listdir(data_dir)\n",
    "print(\"Number of directories:\", len(dirnames))\n",
    "print(\"Directory names:\", dirnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OG8rjgOFlcaV",
    "outputId": "9fc8cf9a-5dd0-4915-d7d3-a6061d5b93a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in rec.autos: 1000\n",
      "Some example filenames: ['101551', '101552', '101553', '101554', '101555']\n"
     ]
    }
   ],
   "source": [
    "#Algunos archivos de la categoria \"com.graphics\"\n",
    "fnames = os.listdir(data_dir / \"rec.autos\")\n",
    "print(\"Number of files in rec.autos:\", len(fnames))\n",
    "print(\"Some example filenames:\", fnames[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ox6s6z9lgps",
    "outputId": "3d4cc9f4-aa9a-49c2-a564-20aff5c67e48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!ogicse!uwm.edu!wupost!uunet!brunix!cs.brown.edu!cs012055\n",
      "From: cs012055@cs.brown.edu (Hok-Chung Tsang)\n",
      "Newsgroups: rec.autos\n",
      "Subject: Re: Saturn's Pricing Policy\n",
      "Message-ID: <1993Apr5.230808.581@cs.brown.edu>\n",
      "Date: 5 Apr 93 23:08:08 GMT\n",
      "Article-I.D.: cs.1993Apr5.230808.581\n",
      "References: <C4oxwp.KKM@news.cso.uiuc.edu> <C4vIr5.L3r@shuksan.ds.boeing.com>\n",
      "Sender: news@cs.brown.edu\n",
      "Organization: Brown Computer Science Dept.\n",
      "Lines: 51\n",
      "\n",
      "In article <C4vIr5.L3r@shuksan.ds.boeing.com>, fredd@shuksan (Fred Dickey) writes:\n",
      "|> CarolinaFan@uiuc (cka52397@uxa.cso.uiuc.edu) wrote:\n",
      "|> : \tI have been active in defending Saturn lately on the net and would\n",
      "|> : like to state my full opinion on the subject, rather than just reply to others'\n",
      "|> : points.\n",
      "|> : \t\n",
      "|> : \tThe biggest problem some people seem to be having is that Saturn\n",
      "|> : Dealers make ~$2K on a car.  I think most will agree with me that the car is\n",
      "|> : comparably priced with its competitors, that is, they aren't overpriced \n",
      "|> : compared to most cars in their class.  I don't understand the point of \n",
      "|> : arguing over whether the dealer makes the $2K or not?  \n",
      "|> \n",
      "|> I have never understood what the big deal over dealer profits is either.\n",
      "|> The only thing that I can figure out is that people believe that if\n",
      "|> they minimize the dealer profit they will minimize their total out-of-pocket\n",
      "|> expenses for the car. While this may be true in some cases, I do not\n",
      "|> believe that it is generally true. I bought a Saturn SL in January of '92.\n",
      "|> AT THAT TIME, based on studying car prices, I decided that there was\n",
      "|> no comparable car that was priced as cheaply as the Saturn. Sure, maybe I\n",
      "|> could have talked the price for some other car to the Saturn price, but\n",
      "|> my out-of-pocket expenses wouldn't have been any different. What's important\n",
      "|> to me is how much money I have left after I buy the car. REDUCING DEALER PROFIT\n",
      "|> IS NOT THE SAME THING AS SAVING MONEY! Show me how reducing dealer profit\n",
      "|> saves me money, and I'll believe that it's important. My experience has\n",
      "|> been that reducing dealer profit does not necessarily save me money.\n",
      "|> \n",
      "|> Fred\n",
      "\n",
      "\n",
      "Say, you bought your Saturn at $13k, with a dealer profit of $2k.\n",
      "If the dealer profit is $1000, then you would only be paying $12k for\n",
      "the same car.  So isn't that saving money?\n",
      "\n",
      "Moreover, if Saturn really does reduce the dealer profit margin by $1000, \n",
      "then their cars will be even better deals.  Say, if the price of a Saturn was\n",
      "already $1000 below market average for the class of cars, then after they\n",
      "reduce the dealer profit, it would be $2000 below market average.  It will:\n",
      "\n",
      "1) Attract even more people to buy Saturns because it would SAVE THEM MONEY.\n",
      " \n",
      "2) Force the competitors to lower their prices to survive.\n",
      "\n",
      "Now, not only will Saturn owners benefit from a lower dealer profit, even \n",
      "the buyers for other cars will pay less.\n",
      "\n",
      "Isn't that saving money?\n",
      "\n",
      "\n",
      "\n",
      "$0.02,\n",
      "doug.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Ejemplo de un texto de la categoría \"com.graphics\"\n",
    "print(open(data_dir / \"rec.autos\" / \"101551\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vUbbjI8plaG0",
    "outputId": "70af29c3-3b1b-4975-e5a1-dad96dc66742"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in talk.politics.misc: 1000\n",
      "Some example filenames: ['124146', '176845', '176846', '176847', '176849']\n"
     ]
    }
   ],
   "source": [
    "#Algunos archivos de la categoria \"talk.politics.misc\"\n",
    "fnames = os.listdir(data_dir / \"talk.politics.misc\")\n",
    "print(\"Number of files in talk.politics.misc:\", len(fnames))\n",
    "print(\"Some example filenames:\", fnames[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "izZGWhpklCbI",
    "outputId": "53eef472-3722-4c2f-ebe0-e2a28035903d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xref: cantaloupe.srv.cs.cmu.edu talk.politics.guns:54219 talk.politics.misc:178463\n",
      "Newsgroups: talk.politics.guns,talk.politics.misc\n",
      "Path: cantaloupe.srv.cs.cmu.edu!magnesium.club.cc.cmu.edu!news.sei.cmu.edu!cis.ohio-state.edu!magnus.acs.ohio-state.edu!usenet.ins.cwru.edu!agate!spool.mu.edu!darwin.sura.net!martha.utcc.utk.edu!FRANKENSTEIN.CE.UTK.EDU!VEAL\n",
      "From: VEAL@utkvm1.utk.edu (David Veal)\n",
      "Subject: Re: Proof of the Viability of Gun Control\n",
      "Message-ID: <VEAL.749.735192116@utkvm1.utk.edu>\n",
      "Lines: 21\n",
      "Sender: usenet@martha.utcc.utk.edu (USENET News System)\n",
      "Organization: University of Tennessee Division of Continuing Education\n",
      "References: <1qpbqd$ntl@access.digex.net> <C5otvp.ItL@magpie.linknet.com>\n",
      "Date: Mon, 19 Apr 1993 04:01:56 GMT\n",
      "\n",
      "[alt.drugs and alt.conspiracy removed from newsgroups line.]\n",
      "\n",
      "In article <C5otvp.ItL@magpie.linknet.com> neal@magpie.linknet.com (Neal) writes:\n",
      "\n",
      ">   Once the National Guard has been called into federal service,\n",
      ">it is under the command of the present. Tha National Guard, though\n",
      ">defined as the \"Militia\" in the statutes, is actually a reserve component\n",
      ">of the United State Army, and was formed pursuant to the power of Congress\n",
      ">to raise and support Armies.\n",
      "\n",
      "       That's the really cute thing about saying the 2nd amendment\n",
      "only covers the national guard, because that would mean that it\n",
      "essentially prohibits the federal government from disarming a branch\n",
      "of the federal government.\n",
      "\n",
      "       Sounds like a real limit to federal power to me.\n",
      "------------------------------------------------------------------------\n",
      "David Veal Univ. of Tenn. Div. of Cont. Education Info. Services Group\n",
      "PA146008@utkvm1.utk.edu - \"I still remember the way you laughed, the day\n",
      "your pushed me down the elevator shaft;  I'm beginning to think you don't\n",
      "love me anymore.\" - \"Weird Al\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Ejemplo de un texto de la categoría \"talk.politics.misc\"\n",
    "print(open(data_dir / \"talk.politics.misc\" / \"178463\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33Ay5U6blCd1",
    "outputId": "a3c1cc96-55c2-4958-bbd7-3b9d064e2a6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing alt.atheism, 1000 files found\n",
      "Processing comp.graphics, 1000 files found\n",
      "Processing comp.os.ms-windows.misc, 1000 files found\n",
      "Processing comp.sys.ibm.pc.hardware, 1000 files found\n",
      "Processing comp.sys.mac.hardware, 1000 files found\n",
      "Processing comp.windows.x, 1000 files found\n",
      "Processing misc.forsale, 1000 files found\n",
      "Processing rec.autos, 1000 files found\n",
      "Processing rec.motorcycles, 1000 files found\n",
      "Processing rec.sport.baseball, 1000 files found\n",
      "Processing rec.sport.hockey, 1000 files found\n",
      "Processing sci.crypt, 1000 files found\n",
      "Processing sci.electronics, 1000 files found\n",
      "Processing sci.med, 1000 files found\n",
      "Processing sci.space, 1000 files found\n",
      "Processing soc.religion.christian, 997 files found\n",
      "Processing talk.politics.guns, 1000 files found\n",
      "Processing talk.politics.mideast, 1000 files found\n",
      "Processing talk.politics.misc, 1000 files found\n",
      "Processing talk.religion.misc, 1000 files found\n",
      "Classes: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "Number of samples: 19997\n",
      "Problematic files: []\n"
     ]
    }
   ],
   "source": [
    "samples = []\n",
    "labels = []\n",
    "class_names = []\n",
    "class_index = 0\n",
    "for dirname in sorted(os.listdir(data_dir)):\n",
    "    class_names.append(dirname)\n",
    "    dirpath = data_dir / dirname\n",
    "    fnames = os.listdir(dirpath)\n",
    "    print(\"Processing %s, %d files found\" % (dirname, len(fnames)))\n",
    "    for fname in fnames:\n",
    "        fpath = dirpath / fname\n",
    "        f = open(fpath, encoding=\"latin-1\")\n",
    "        content = f.read()\n",
    "        lines = content.split(\"\\n\")\n",
    "        lines = lines[10:]\n",
    "        content = \"\\n\".join(lines)\n",
    "        samples.append(content)\n",
    "        labels.append(class_index)\n",
    "    class_index += 1\n",
    "\n",
    "print(\"Classes:\", class_names)\n",
    "print(\"Number of samples:\", len(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-dphjZ1PMcCV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2pmvE6gMcxT"
   },
   "source": [
    "# Mezclando los datos para separarlos en Traning y Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "DYX7x-k_lCgZ"
   },
   "outputs": [],
   "source": [
    "# Shuffle the data\n",
    "seed = 1337\n",
    "rng = np.random.RandomState(seed)\n",
    "rng.shuffle(samples)\n",
    "rng = np.random.RandomState(seed)\n",
    "rng.shuffle(labels)\n",
    "\n",
    "# Extract a training & validation split\n",
    "validation_split = 0.2\n",
    "num_validation_samples = int(validation_split * len(samples))\n",
    "train_samples = samples[:-num_validation_samples]\n",
    "val_samples = samples[-num_validation_samples:]\n",
    "train_labels = labels[:-num_validation_samples]\n",
    "val_labels = labels[-num_validation_samples:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMrE0T4wMj09"
   },
   "source": [
    "¿Por qué mezclamos los datos antes de separarlos en entrenamiento y validación?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "OHjeoH7Rp1jm"
   },
   "outputs": [],
   "source": [
    "#Tu respuesta aqui\n",
    "\n",
    "#Es necesario dividirlas para asegurarnos que las clases estén correctamente balanceadas tanto en la distribución que se usará para entrenamiento como para la de validación. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mBO_XEZAp1vK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QJ2QGCeGp1yF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IktOtKfpNx8E"
   },
   "source": [
    "# Tokenización de las palabras con TextVectorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "QjHgQPX8lCjO"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=200)\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(train_samples).batch(128)\n",
    "vectorizer.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vIWC37s5smZ4",
    "outputId": "249ccbb6-7ef9-4659-a10a-2c554f337dbc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'the', 'to', 'of']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_vocabulary()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vit8TPqTvmwS",
    "outputId": "bc809473-254a-4114-cdf3-759992afdb3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NmftvUeeF65s"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yttb9K8vssAz"
   },
   "source": [
    "Pregunta. En la construcción del vocabulario hemos limitado el número de tokens ¿Podrías indicar el número de token diferentes o tamaño del vocabulario sin limitar el número de tokens? Es decir, ¿Cuántas palabras diferentes existen en los documentos procesados como instancias?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "SZIgywwYquDE"
   },
   "outputs": [],
   "source": [
    "#Tu código aqui\n",
    "\n",
    "#Para responder a la pregunta hay que hacer uso nuevo del método TextVectorization pero en esta ocasión no limitarle el número de tokens, es decir, eliminando donde indica max_tokens=20.000. A continuación se deja el código para resolver esta pregunta.\n",
    "vectorizer2 = TextVectorization(output_sequence_length=200)\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(train_samples).batch(128)\n",
    "vectorizer2.adapt(text_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xc2 in position 6: unexpected end of data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mvectorizer2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_vocabulary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m5\u001b[39m]\n",
      "File \u001b[1;32md:\\unir\\segundo\\sc\\practica3\\deeplearning\\lib\\site-packages\\keras\\layers\\preprocessing\\text_vectorization.py:487\u001b[0m, in \u001b[0;36mTextVectorization.get_vocabulary\u001b[1;34m(self, include_special_tokens)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_vocabulary\u001b[39m(\u001b[38;5;28mself\u001b[39m, include_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    479\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the current vocabulary of the layer.\u001b[39;00m\n\u001b[0;32m    480\u001b[0m \n\u001b[0;32m    481\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;124;03m        returned vocabulary will not include any padding or OOV tokens.\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 487\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lookup_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_vocabulary\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude_special_tokens\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\unir\\segundo\\sc\\practica3\\deeplearning\\lib\\site-packages\\keras\\layers\\preprocessing\\index_lookup.py:385\u001b[0m, in \u001b[0;36mIndexLookup.get_vocabulary\u001b[1;34m(self, include_special_tokens)\u001b[0m\n\u001b[0;32m    382\u001b[0m     keys, values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlookup_table\u001b[38;5;241m.\u001b[39mexport()\n\u001b[0;32m    383\u001b[0m     vocab, indices \u001b[38;5;241m=\u001b[39m (values, keys) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvert \u001b[38;5;28;01melse\u001b[39;00m (keys, values)\n\u001b[0;32m    384\u001b[0m     vocab, indices \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 385\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensor_vocab_to_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    386\u001b[0m         indices\u001b[38;5;241m.\u001b[39mnumpy(),\n\u001b[0;32m    387\u001b[0m     )\n\u001b[0;32m    388\u001b[0m lookup \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mdefaultdict(\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moov_token, \u001b[38;5;28mzip\u001b[39m(indices, vocab)\n\u001b[0;32m    390\u001b[0m )\n\u001b[0;32m    391\u001b[0m vocab \u001b[38;5;241m=\u001b[39m [lookup[x] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocabulary_size())]\n",
      "File \u001b[1;32md:\\unir\\segundo\\sc\\practica3\\deeplearning\\lib\\site-packages\\keras\\layers\\preprocessing\\string_lookup.py:416\u001b[0m, in \u001b[0;36mStringLookup._tensor_vocab_to_numpy\u001b[1;34m(self, vocabulary)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_tensor_vocab_to_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m, vocabulary):\n\u001b[0;32m    414\u001b[0m     vocabulary \u001b[38;5;241m=\u001b[39m vocabulary\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    415\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[1;32m--> 416\u001b[0m         [tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mas_text(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m vocabulary]\n\u001b[0;32m    417\u001b[0m     )\n",
      "File \u001b[1;32md:\\unir\\segundo\\sc\\practica3\\deeplearning\\lib\\site-packages\\keras\\layers\\preprocessing\\string_lookup.py:416\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_tensor_vocab_to_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m, vocabulary):\n\u001b[0;32m    414\u001b[0m     vocabulary \u001b[38;5;241m=\u001b[39m vocabulary\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    415\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[1;32m--> 416\u001b[0m         [\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m vocabulary]\n\u001b[0;32m    417\u001b[0m     )\n",
      "File \u001b[1;32md:\\unir\\segundo\\sc\\practica3\\deeplearning\\lib\\site-packages\\tensorflow\\python\\util\\compat.py:110\u001b[0m, in \u001b[0;36mas_text\u001b[1;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[0;32m    108\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m bytes_or_text\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(bytes_or_text, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m--> 110\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbytes_or_text\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    112\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected binary or unicode string, got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m bytes_or_text)\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xc2 in position 6: unexpected end of data"
     ]
    }
   ],
   "source": [
    "vectorizer2.get_vocabulary()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2O-FXA9wPVkg"
   },
   "source": [
    "# Viendo la salida de Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rseIF0fLmyJ0",
    "outputId": "b17fce20-cb66-451a-b0ca-122a9f51de3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   2, 3644, 1711,   15,    2, 6427], dtype=int64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = vectorizer([[\"the cat sat on the mat\"]])\n",
    "output.numpy()[0, :6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wsr4AQtBFArV",
    "outputId": "2cf81b76-07e9-4dc4-b4f1-231e1c2934c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 200), dtype=int64, numpy=\n",
       "array([[   2, 3456, 1682,   15,    2, 5776,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0]], dtype=int64)>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "SL5ag8UamzwL"
   },
   "outputs": [],
   "source": [
    "voc = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08v8SKcsn3lf",
    "outputId": "62a2aff9-c4eb-45a4-b6d6-68b87cdcff19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3644, 1711, 15, 2, 6427]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"]\n",
    "[word_index[w] for w in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Zau4Xlu5F_IB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWxZ5Z0sF_d8"
   },
   "source": [
    "Pregunta. La salida de vectorizer() para codificar los tokens [\"El\", \"gato\", \"está\", \"sobre\", \"el\", \"tejado\"] es la siguiente [1, 121, 405, 1, 45, 4561]. Si cada uno de los valores indica el índice en el que se encuentra cada palabra en el array creado para codificarla. ¿Podría ser correcta esta salida?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "W9Xfg6MJFMZF"
   },
   "outputs": [],
   "source": [
    "#Tu respuesta aqui\n",
    "\n",
    "#No es correcta la salida porque como se puede ver el token “El” ha sido codificado con un 2 (es decir, con todo ceros salvo la un 1 en la posición 2) y el token “sobre” también ha sido codificado con un 2, es decir, exactamente igual que el token “El”. Cada “token” debe tener una codificación diferente. Para más error, se puede ver que “El” posteriormente tiene asignada otra codificación diferente 45 (es decir, un vector con todo ceros salvo un uno en la posición 45. Esto no es posible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "yXlhllZAFMb7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "YWalbsjUKTLy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eBhadrvOTNZ"
   },
   "source": [
    "# Tokenización de los datos de entrenamiento y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "W26LUr2dKTOj"
   },
   "outputs": [],
   "source": [
    "x_train = vectorizer(np.array([[s] for s in train_samples])).numpy()\n",
    "x_val = vectorizer(np.array([[s] for s in val_samples])).numpy()\n",
    "\n",
    "y_train = np.array(train_labels)\n",
    "y_val = np.array(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PNu69FgnOarK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ur0mBBesOa3s"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q3QVIb84Olda"
   },
   "source": [
    "#Creación del modelo con un embedding hecho a mano con redes neuronales clásicas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "VTDrdvQyOlda"
   },
   "outputs": [],
   "source": [
    "modeloEmbeddingManual = keras.models.Sequential()\n",
    "modeloEmbeddingManual.add(keras.layers.Embedding(20000, 10, input_length=200))\n",
    "modeloEmbeddingManual.add(keras.layers.Flatten())\n",
    "modeloEmbeddingManual.add(keras.layers.Dense(512, activation='relu'))\n",
    "modeloEmbeddingManual.add(keras.layers.Dropout(0.3))\n",
    "modeloEmbeddingManual.add(keras.layers.Dense(20, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qD_hqn2sOlda",
    "outputId": "2c626089-182a-49dd-91f2-508bb63d374c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "125/125 [==============================] - 2s 5ms/step - loss: 2.7250 - acc: 0.1313 - val_loss: 2.3082 - val_acc: 0.2331\n",
      "Epoch 2/20\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 1.9168 - acc: 0.3764 - val_loss: 1.7515 - val_acc: 0.4106\n",
      "Epoch 3/20\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 1.2874 - acc: 0.6108 - val_loss: 1.3574 - val_acc: 0.5459\n",
      "Epoch 4/20\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.8173 - acc: 0.7655 - val_loss: 1.1467 - val_acc: 0.6199\n",
      "Epoch 5/20\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.5309 - acc: 0.8477 - val_loss: 1.0378 - val_acc: 0.6532\n",
      "Epoch 6/20\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.3659 - acc: 0.8987 - val_loss: 1.0345 - val_acc: 0.6612\n",
      "Epoch 7/20\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.2644 - acc: 0.9246 - val_loss: 1.0548 - val_acc: 0.6799\n",
      "Epoch 8/20\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.2041 - acc: 0.9403 - val_loss: 1.0598 - val_acc: 0.6802\n",
      "Epoch 9/20\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.1694 - acc: 0.9491 - val_loss: 1.0733 - val_acc: 0.6899\n",
      "Epoch 10/20\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.1393 - acc: 0.9577 - val_loss: 1.1132 - val_acc: 0.6932\n",
      "Epoch 11/20\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.1213 - acc: 0.9599 - val_loss: 1.1287 - val_acc: 0.7007\n",
      "Epoch 12/20\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.1091 - acc: 0.9627 - val_loss: 1.1564 - val_acc: 0.7034\n",
      "Epoch 13/20\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.1037 - acc: 0.9637 - val_loss: 1.1694 - val_acc: 0.7077\n",
      "Epoch 14/20\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0908 - acc: 0.9654 - val_loss: 1.1954 - val_acc: 0.7054\n",
      "Epoch 15/20\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0862 - acc: 0.9660 - val_loss: 1.2224 - val_acc: 0.7037\n",
      "Epoch 16/20\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0839 - acc: 0.9656 - val_loss: 1.2409 - val_acc: 0.6982\n",
      "Epoch 17/20\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0790 - acc: 0.9662 - val_loss: 1.2449 - val_acc: 0.7074\n",
      "Epoch 18/20\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0755 - acc: 0.9665 - val_loss: 1.2654 - val_acc: 0.7069\n",
      "Epoch 19/20\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0731 - acc: 0.9668 - val_loss: 1.3023 - val_acc: 0.7067\n",
      "Epoch 20/20\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0709 - acc: 0.9679 - val_loss: 1.3395 - val_acc: 0.7064\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 200, 10)           200000    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2000)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1024512   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                10260     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,234,772\n",
      "Trainable params: 1,234,772\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "modeloEmbeddingManual.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "modeloEmbeddingManual.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
    "modeloEmbeddingManual.fit(x_train, y_train, batch_size=128, epochs=20, validation_data=(x_val, y_val))\n",
    "print(modeloEmbeddingManual.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AT8KYdHaOh31"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4x_4eXJVrnX"
   },
   "source": [
    "#Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "fgg7KnoioNYc",
    "outputId": "d9e16bfc-5e8d-4bf4-8f0a-c45afbf61cd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 105ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'comp.graphics'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
    "x = vectorizer(string_input)\n",
    "preds = modeloEmbeddingManual(x)\n",
    "end_to_end_model = keras.Model(string_input, preds)\n",
    "\n",
    "probabilities = end_to_end_model.predict(\n",
    "    [[\"this message is about computer graphics and 3D modeling\"]]\n",
    ")\n",
    "\n",
    "class_names[np.argmax(probabilities[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "R-EXfK6qoSAd",
    "outputId": "49559598-4c87-49bd-b4f5-22b3822ad301"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'misc.forsale'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities = end_to_end_model.predict(\n",
    "    [[\"we are talking about politics\"]]\n",
    ")\n",
    "\n",
    "class_names[np.argmax(probabilities[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "QByfYDv4rGqv",
    "outputId": "8a90b8db-52cb-4b35-ece1-8daa7b4e61ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'misc.forsale'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities = end_to_end_model.predict(\n",
    "    [[\"we are talking about religion\"]]\n",
    ")\n",
    "\n",
    "class_names[np.argmax(probabilities[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "9ceed0nfrGtd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "MdD9NHIKXOdl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
