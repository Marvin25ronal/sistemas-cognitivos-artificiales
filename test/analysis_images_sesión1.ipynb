{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yB9aFIMOvU2M"
      },
      "outputs": [],
      "source": [
        "# Cargar el framework tensorflow y verificar su versión\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>MNIST</h1>"
      ],
      "metadata": {
        "id": "hHMc68OkUArR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b>tf.keras.datasets</b> contiene varios datasets para generar modelos de clasificación, regresión y texto.\n",
        "\n",
        "*   <b>boston_housing</b>: Conjunto de datos para la predicción de precios de las casas en Boston.\n",
        "*   <b>cifar10</b>: Conjunto de imágenes a color (32x32x3) de 10 tipos de objetos.\n",
        "*   <b>cifar100</b>: Conjunto de imágenes a color (32x32x3) de 100 tipos de objetos.\n",
        "*   <b>fashion_mnist</b>: Conjunto de imágenes de prendas de vestir en escala de grises de 28x28.\n",
        "*   <b>imdb</b>: Conjunto de reseñas de películas con un sentimiento positivo o negativo.\n",
        "*   <b>mnist</b>: Conjunto de imágenes de dígitos escritos a mano en escala de grises de 28x28.\n",
        "*   <b>reuters</b>: Conjunto de datos de noticias de Reuters.\n",
        "\n",
        "Para más información ver https://keras.io/api/datasets/\n",
        "\n",
        "<hr>\n",
        "\n",
        "**MNIST** es una base de datos de dígitos escritos a mano, de 0 a 9, que se compone de 70000 imágenes de 28x28, donde cada pixel contiene un valor de 0 a 255. El dataset se divide en un conjunto de entrenamiento de 60000 imágenes, y un conjunto de prueba de 10000 imágenes.\n",
        "\n",
        "**MNIST** tienen 10 clases, esto es, dígitos del 0 al 9\n",
        "\n",
        "http://yann.lecun.com/exdb/mnist/\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "I6B0iZa_RL6J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> Cargando el dataset MNIST </h2>"
      ],
      "metadata": {
        "id": "8KVKTgFMp2F2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se importa el dataset MNIST\n",
        "digit_mnist = tf.keras.datasets.cifar100\n",
        "\n",
        "\n",
        "# Se cargan los conjuntos de entrenamiento (*_train_whole) y de validación (*_test) en variables separadas\n",
        "(X_train_whole, y_train_whole), (X_test, y_test) = digit_mnist.load_data()\n"
      ],
      "metadata": {
        "id": "i6Wiczf4wFOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Impresión del número de imagenes del conjunto de entrenamiento y validación\n",
        "\n",
        "print(f'Numero de imagenes para entrenamiento {X_train_whole.shape[0]}, de tamaño {X_train_whole.shape[1]}x{X_train_whole.shape[2]}')"
      ],
      "metadata": {
        "id": "I3354S_Mwy8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Visualización del dataset </h1>"
      ],
      "metadata": {
        "id": "J0YWc8zBjWc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Tamaño de la figura\n",
        "w = 9\n",
        "h = 9\n",
        "\n",
        "# Número de columnas y filas del subplot\n",
        "cols = 4\n",
        "rows = 4\n",
        "\n",
        "# Creación de la figura\n",
        "fig = plt.figure(figsize=(w, h))\n",
        "\n",
        "for i in range(1, cols*rows+1):\n",
        "  img = X_train_whole[i]\n",
        "  fig.add_subplot(rows, cols, i)\n",
        "  # Mapa de color\n",
        "  # \"Blues\", \"Blues_r\"\n",
        "  # \"viridis\" (G, Y, B), \"viridis_r\"\n",
        "  plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zXLcxwoitLFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# linewidth - número de caracteres por línea\n",
        "np.set_printoptions(linewidth=200)\n",
        "print(y_train_whole[0])\n",
        "print(X_train_whole[0])\n",
        "\n",
        "plt.imshow(X_train_whole[0], cmap=\"Blues\")"
      ],
      "metadata": {
        "id": "9WJiJCsejgLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tipo de datos"
      ],
      "metadata": {
        "id": "lfE_M8X4sXfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_whole.dtype"
      ],
      "metadata": {
        "id": "eF72P2Ttw9l1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clases, valor  = np.unique(y_train_whole, return_counts=True)\n",
        "\n",
        "print(clases)\n",
        "\n",
        "w = 13\n",
        "h = 7\n",
        "plt.figure(figsize=(w,h))\n",
        "plt.title(\"Elementos por clase\", fontsize=18)\n",
        "plt.xticks(range(len(clases)))\n",
        "plt.bar(clases, valor)#, color=\"green\")"
      ],
      "metadata": {
        "id": "KaVfdm4QXUWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset para entrenamiento"
      ],
      "metadata": {
        "id": "LbwfZKPgshUi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para el entrenamiento del modelo, dividir *X_train_whole* y *y_train_whole* en dos conjuntos: el de entrenamiento y el de validación. Generalmente se toma el 80% para entrenamiento y el resto (20%) para validación.\n",
        "\n",
        "**División lineal**\n",
        "\n",
        "Se realiza de manera \"manual\", esto es mediante índices.\n",
        "\n",
        "Para nuestro conjunto, se asume que *X_train_whole* es un arreglo de imágenes y se divide mediante un índice, donde la primera parte es para entrenar y la segunda para validar."
      ],
      "metadata": {
        "id": "2abFWJ97sfMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_valid, X_train = X_train_whole[:12000], X_train_whole[12000:]\n",
        "y_valid, y_train = y_train_whole[:12000], y_train_whole[12000:]\n",
        "print(f'Número de elementos para entrenar: {X_train.shape}')\n",
        "print(f'Número de elementos para validar: {X_valid.shape}')"
      ],
      "metadata": {
        "id": "FmXje7LExDBl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}